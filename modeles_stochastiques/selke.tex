\section{La construction de Selke}

Une construction équivalente, proposée par Sellke en 1983, se base sur l’idée d’affecter à chaque individu une capacité de résistance à l’épidémie et de définir, à partir du nombre d’infectés, une pression de l’épidémie et un critère d’infection sur la résistance de l’individu. \\
Pour y arriver, les chaînes de Markov sont utilisées pour modéliser l’évolution de l’épidémie au fil du temps, en prenant en compte les transitions entre les différents états de l’épidémie (susceptible, infecté, rétabli). \\
De plus, le processus de Poisson précedemment définie est aussi utilisé afin de modéliser le nombre d’infections qui se produisent dans un intervalle de temps donné, en supposant que les infections se produisent de manière aléatoire et indépendante les unes des autres.\\

De plus cette construction permet aussi d’identifier un paramètre important quand il s’agit de modéliser une épidémie : sa taille finale. Ici, l’expression de la taille finale de l’épidémie dépend du nombre de reproductions de base $R_0$, qui est le nombre moyen de personnes qu’un individu infecté infecte au début de l’épidémie, défini par $R_0 = \lambda i$\\
Plus le nombre de reproductions de base est élevé, plus la taille finale de l’épidémie sera grande.\\
L’expression de la taille finale de l’épidémie peut être calculée à partir de l’équation $1 - \tau = e - R_0\tau$, où $\tau$ est la proportion de la population qui sera infectée à la fin de l’épidémie.


\subsubsection{Chaine de Markov}
Rappellons cette notion mathématique.\\
Une chaîne de Markov est un processus aléatoire à temps discret dont la principale caractéristique est l’absence de mémoire et l’existence de probabilités de transition entre les états de la chaîne. Cela signifie que seul l’état actuel du processus a une influence sur l’état qui va suivre.

En considérant S un ensemble fini (ou dénombrable) et $(X_n)_{n \in \boldsymbol{N}}$ une suite de variables aléatoires définie sur le même univers $\Omega$ munit de la mesure de probabilité $\mathbb{P}$ et à valeurs dans S. $(X_n)$ est chaîne de Markov homogéne si :

\begin{itemize}
    \item \textbf{Propriété de Markov} : $\forall n \in \boldsymbol{N}$ et $(x_i)^n \in S^n (i \in [[0, n+1]])$ \\
$$ \mathbb{P}(X_{n+1} = x_{n+1} | X_{0:n} = x_{0:n}) = \mathbb{P}(X_{n+1} = x_{n+1} | X_n = x_n) $$
    \item \textbf{Homogénéité} : $\mathbb{P}(X_{n+1} = y | X_n = x)$ ne dépend pas de n, $\forall (x, y) \in S^2$. On note alors $p(x, y)$ cette probabilité.
\end{itemize}

La loi de $X_0$ est appelée loi initiale de la chaîne de Markov, $P = (p(x, y))_{x,y \in S}$ est appelée matrice de transition.



\subsection{Définition du modèle}

Ainsi, après avoir vu tous les outils qui sont utilisés au sein de ce modèle, revenons-en à sa définition en elle même. \\
Plus précisément, revenons-en à ses particularités qui sont les notions de pression et résistance à l'épidémie. On va indexer la population de la façon suivante :\\
-Les infectés initiaux seront notés $-(m-1), -(m-2), ...  -1, 0$\\
-Les susceptibles de 1 à $n$.\\
On associe à chaque individu un temps de contagion $I-(m-1), ...I_n$ indépendantes et identiquements distribuées de loi I. A chaque susceptible on associe aussi des seuils $Q_1, Q_n$ indépendants et identiquements distribués suivant une loi exponentielle de paramètre 1.

On peut alors définir à chaque temps $t$, avec $Y(t)$ le nombre d'infectés, la pression de l'épidémie :
$$ A(t) = \frac{\lambda}{n} \int^t_0 Y(u)du $$

Un susceptible $j$ est alors infecté quand la pression dépasse le seuil $Q_j$. Il devient contagieux pendant le temps $I_j$

\subsection{Taille finale de l'épidémie}

On réordonne les individus suceptibles en fonction de leur seuil croissant que l'on noteras $Q_1$, ..., $Q_n$. \\
On peut noté que l'épidémie s'arrête lorsque la pression exercée par les individus infectés n'est pas suffisante pour atteindre le prochain seuil. Chaque individus infecté participe à la pression ce qui nous donne la pression exercée aprés la iéme infection : $ \frac{\lambda}{n} \sum^i_{j = - (m-1)} I_j $. Si $Q_{i+1}$ est supérieur à la valeur de la dernière expression, l'épidémie s'arrête.\\
On a donc que la taille finale de l'épidémie $Z$ est :
$$ Z = \min \{\frac{\lambda}{n} \sum^i_{j = - (m-1)} I_j \} $$

\begin{theorem}[Identité de Wald]
Soit une épidémie $E_{n,m}(\lambda, I)$ de pression finale Z.Alors $ \forall \theta \geq 0$, on a:\\

$$\mathbb{E}[ \frac{ e^{-\theta P(\infty)} }{ \Phi( \frac{\lambda \theta}{n})^{Z + m} } ] = 1 $$
où $ \Phi(\theta) = \mathbb{E}[e^{-\theta T}] $ est la fonction de transformée de Laplace de T.
\end{theorem}

\begin{proof}
Calculons $ \Phi( \frac{\lambda \theta}{n})^{n + m}$\\

En utilisant la fonction de transformée de Laplace, on obtient :
	\begin{itemize}[label=$\bullet$]
	\item $ \Phi( \frac{\lambda \theta}{n})^{n + m} = \mathbb{E}[e^{-(\frac{\lambda \theta}{n}) \sum^n_{j = - (m-1)} I_j }]$
	\end{itemize}
En réalisant un changement des bornes à l'insertion de la formule de la taille finale d'une épidémie,on se retrouve avec :
	\begin{itemize}[label=$\bullet$]
	\item  $ \mathbb{E}[e^{-(\frac{\lambda \theta}{n}) \sum^i_{j = - (m-1)} I_j }]= \mathbb{E}[e^{- \theta(Z+\frac{\lambda}{n} \sum^n_{j = Z+1} I_j }]$
	\end{itemize}
Ce qui nous permet de déduire l'égalité suivant grâce à la fonction de transformée de Laplace :
	\begin{itemize}[label=$\bullet$]
	\item $\mathbb{E}[e^{- \theta(Z+\frac{\lambda}{n} \sum^n_{j = Z+1} I_j }]=\mathbb{E}[e^{- \theta Z}\Phi( \frac{\lambda \theta}{n})^{n - Z}]$
	\end{itemize}	
On se retrouve ainsi avec l'égalité :	
	\begin{itemize}[label=$\bullet$]
	\item $\Phi( \frac{\lambda \theta}{n})^{n + m} =\mathbb{E}[e^{- \theta Z}\Phi( \frac{\lambda \theta}{n})^{n - Z}] $
	\end{itemize}
En divisant les deux côtés de l'égalité par $\Phi( \frac{\lambda \theta}{n})^{n + m}$,on se retrouve finalement avec l'identité de Wald :
	\begin{itemize}[label=$\bullet$]
	\item $\mathbb{E}[ \frac{ e^{-\theta P(\infty)} }{ \Phi( \frac{\lambda \theta}{n})^{Z + m} } ] = 1$
	\end{itemize}	
\end{proof}

De ce précédent théorème, on peut obtenir notre prochain théorème :
\begin{theorem}
Dans ce modèle d'épidémie, les probabilitées $P_{k}^{n}$ que k individus initialement susceptibles soit finalement infectés sont décrites par l'expression :

$$\sum_{k=0}^{l}\binom{N-i}{k-i}\frac{P_{k}^{n}}{\Phi( \frac{\lambda (N-k)}{n})^{i + m} }=\binom{N}{i}$$
\end{theorem}

\begin{proof}
Pour démontrer ce résultat nous allons avoir besoin de l'identitté de Wald, ainsi qu'une expression issu de la littérature mathématique que nous allons admettre :
$ \frac{{p_{i}}^{N}}{\binom{N}{i}}= \frac{{p_{i}}^{k}}{\binom{k}{i}}\left ( \exp(-(N-k)A^{k}|Z^{k}=i)  \right )$\\
Même si nous l'admetteons nous pouvons tout de même l'expliquer.A la gauche de l'égalite se trouve la probabilité qu'un groupe de taille i soit infecté et personne d'autre.A la droite de l'égalité se trouve deux évenements bien spécifiques.Le premier est la probabilité qu'un sous groupe composé de i personnes soit infectée parmi un groupe de k personnes,tandis que le second évènement est la probabilité que toute personne extérieur au groupe de k personnes ne soient pas infectées,avec une pression totale de l'épidémie égal à i.\\

Désormais nous posons $\theta = N-k$,ainsi qu'une pression épidémique $Z^{k} = i$,et injectons ces données dans l'identité de Wald.
Nous nous retrouvons donc avec :
\begin{itemize}[label=$\bullet$]
	\item $\sum_{i=0}^{k} \frac{ \mathbb{E}[e^{-(N-k) A^{k}}|Z^{k}=i ]}{ \Phi( \frac{\lambda (N-k)}{n})^{i + m} } ]p{_{i}}^{k} = 1$\\
	Puis on injecte l'équation précedemment admis :\\
	\item $\sum_{i=0}^{k}\frac{\binom{k}{i}p{_{i}}^{N}}{\binom{N}{i}\Phi( \frac{\lambda (N-k)}{n})^{i + m} } = 1$\\
	Or,\\
	\item $\binom{k}{i}/\binom{N}{i} = \binom{N-i}{k-i}\binom{N}{k}$\\
	Ainsi,on se retrouve avec :\\
	\item $\sum_{k=0}^{l}\binom{N-i}{k-i}\frac{P_{k}^{n}}{\Phi( \frac{\lambda (N-k)}{n})^{i + m} }=\binom{N}{i}$
\end{itemize}	


\end{proof}


